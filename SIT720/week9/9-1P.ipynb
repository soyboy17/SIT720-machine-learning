{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Question 1: Load  \"data.csv\" dataset and create an ensemble ML model for predicting target variable (Result). Report the performance of the model using appropriate metrics**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 17 rows with 39 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>FNL1</th>\n",
       "      <th>FNL2</th>\n",
       "      <th>FSP.1</th>\n",
       "      <th>FSW.1</th>\n",
       "      <th>SSP.1</th>\n",
       "      <th>SSW.1</th>\n",
       "      <th>ACE.1</th>\n",
       "      <th>DBF.1</th>\n",
       "      <th>WNR.1</th>\n",
       "      <th>...</th>\n",
       "      <th>BPC.2</th>\n",
       "      <th>BPW.2</th>\n",
       "      <th>NPA.2</th>\n",
       "      <th>NPW.2</th>\n",
       "      <th>TPW.2</th>\n",
       "      <th>ST1.2</th>\n",
       "      <th>ST2.2</th>\n",
       "      <th>ST3.2</th>\n",
       "      <th>ST4.2</th>\n",
       "      <th>ST5.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>173</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>30.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>152</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result  FNL1  FNL2  FSP.1  FSW.1  SSP.1  SSW.1  ACE.1  DBF.1  WNR.1  ...  \\\n",
       "0       0     2     3     68     73     32     24      5    3.0     41  ...   \n",
       "1       0     2     3     53     46     47     35      7    7.0     47  ...   \n",
       "2       1     3     2     57     62     43     43     13    0.0     50  ...   \n",
       "3       0     2     3     64     63     36     23      7    4.0     49  ...   \n",
       "4       0     2     3     60     58     40     21     13    8.0     40  ...   \n",
       "\n",
       "   BPC.2  BPW.2  NPA.2  NPW.2  TPW.2  ST1.2  ST2.2  ST3.2  ST4.2  ST5.2  \n",
       "0     10     17   25.0   36.0    173      3    7.0    6.0    6.0    6.0  \n",
       "1      7     19   30.0   43.0    152      6    3.0    4.0    6.0    6.0  \n",
       "2      3      7   28.0   44.0    152      1    7.0    6.0    6.0    6.0  \n",
       "3      6     12   28.0   37.0    131      6    7.0    4.0    0.0    6.0  \n",
       "4      5      9   31.0   46.0    153      1    4.0    6.0    6.0    6.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/data_9.csv\")\n",
    "\n",
    "# Print dimensions\n",
    "rows, cols = df.shape\n",
    "print(\"Data has {} rows with {} columns\".format(rows, cols))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Result', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Countplot for target variable\n",
    "sns.countplot(x='Result', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is of type: <class 'pandas.core.frame.DataFrame'>\n",
      "y is of type: <class 'pandas.core.series.Series'>\n",
      "Unique labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into X and y\n",
    "X = df.drop('Result', axis=1)\n",
    "y = df.Result\n",
    "\n",
    "# Print the type for X and y\n",
    "print (\"X is of type: {}\".format(type(X)))\n",
    "print (\"y is of type: {}\".format(type(y)))\n",
    "\n",
    "# Print the unique labels in y\n",
    "print (\"Unique labels: {}\".format(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of X_train samples:  13\n",
      "Number of X_test samples:  4\n"
     ]
    }
   ],
   "source": [
    "# Split the data into test and train (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the  number of samples in train and test data groups\n",
    "print(\"Number of X_train samples: \", X_train.shape[0])\n",
    "print(\"Number of X_test samples: \", X_test.shape[0])\n",
    "\n",
    "## Very small sample size, could be a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 100 estimators: 1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Performance metrics - choose from accuracy, precision, recall, f1-score, ROC AUC, AUC-PR, confusion matrix, feature importance, OOB error, specificity, matthews correlation coefficient\n",
    "pred = rf_clf.predict(X_test)\n",
    "print(\"Accuracy for {} estimators: {}\\n\".format(100, accuracy_score(y_test, pred)))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest importances: \n",
      " FNL1     0.085030\n",
      "FNL2     0.174911\n",
      "FSP.1    0.011231\n",
      "FSW.1    0.004583\n",
      "SSP.1    0.008577\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate feature importances\n",
    "importances = rf_clf.feature_importances_ # Gini importance\n",
    "# print(importances)\n",
    "\n",
    "forest_importances = pd.Series(importances, index=list(X_train.columns))            # Associate each feature with its importance\n",
    "std = np.std([tree.feature_importances_ for tree in rf_clf.estimators_], axis=0)    # Compute standard deviation across trees - helps to understand the variability of feature importance estimates across different trees\n",
    "print(\"Forest importances: \\n\", forest_importances.head())\n",
    "\n",
    "# Plot feature importances\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n",
    "\n",
    "## Most important features for making predictions with this model is FNL2 (0.175), followed by FNL1 (0.085) and FSP.1 (0.011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Question 2: Have you used any hyperparameter tuning while building the model in Q1? If yes, then plot the performances that were obtained at different steps of optimisation. Otherwise, create an optimised model and compare performance with Q1**_\n",
    "\n",
    "Hyperparameters used in Q1:\n",
    "n_estimators - set to 100 (which also is the default value if no value is specified)\n",
    "random_state - I set this value to ensure I get the same results each time I run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 10 estimators: 0.750\n",
      "\n",
      "Classification report for 10 estimators:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.75      0.83      0.73         4\n",
      "weighted avg       0.88      0.75      0.77         4\n",
      "\n",
      "Accuracy for 20 estimators: 0.750\n",
      "\n",
      "Classification report for 20 estimators:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.75      0.83      0.73         4\n",
      "weighted avg       0.88      0.75      0.77         4\n",
      "\n",
      "Accuracy for 50 estimators: 1.000\n",
      "\n",
      "Classification report for 50 estimators:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 100 estimators: 1.000\n",
      "\n",
      "Classification report for 100 estimators:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 500 estimators: 1.000\n",
      "\n",
      "Classification report for 500 estimators:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 1000 estimators: 1.000\n",
      "\n",
      "Classification report for 1000 estimators:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 2000 estimators: 1.000\n",
      "\n",
      "Classification report for 2000 estimators:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run RandomForestClassifier to find the optimum number of estimators (the number of trees in the forest)\n",
    "\n",
    "n_estimators = [10, 20, 50, 100, 500, 1000, 2000]\n",
    "\n",
    "for n in n_estimators:\n",
    "    rf_clf = RandomForestClassifier(n_estimators=n, random_state = 42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    pred = rf_clf.predict(X_test)\n",
    "    print(\"Accuracy for {} estimators: {:.3f}\\n\".format(n, accuracy_score(y_test, pred)))\n",
    "    print(\"Classification report for {} estimators:\".format(n))\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "## Model performs acceptably with 10 estimators (without overfitting) and approaches perfect accuracy with values over 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for gini criterion: 1.000\n",
      "\n",
      "Classification report for gini criterion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for entropy criterion: 1.000\n",
      "\n",
      "Classification report for entropy criterion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for log_loss criterion: 1.000\n",
      "\n",
      "Classification report for log_loss criterion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run RandomForestClassifier to find the optimum value for criterion - function that measures the quality of a split\n",
    "\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "for c in criterion:\n",
    "    rf_clf = RandomForestClassifier(criterion=c, random_state = 42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    pred = rf_clf.predict(X_test)\n",
    "    print(\"Accuracy for {} criterion: {:.3f}\\n\".format(c, accuracy_score(y_test, pred)))\n",
    "    print(\"Classification report for {} criterion:\".format(c))\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "## Model performs will with all three criterions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sqrt max_features: 1.000\n",
      "\n",
      "Classification report for sqrt max_features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for log2 max_features: 1.000\n",
      "\n",
      "Classification report for log2 max_features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for None max_features: 1.000\n",
      "\n",
      "Classification report for None max_features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run RandomForestClassifier to find the optimum value for max_features - the number of features to consider at each split\n",
    "\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "\n",
    "for m in max_features:\n",
    "    rf_clf = RandomForestClassifier(max_features=m, random_state = 42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    pred = rf_clf.predict(X_test)\n",
    "    print(\"Accuracy for {} max_features: {:.3f}\\n\".format(m, accuracy_score(y_test, pred)))\n",
    "    print(\"Classification report for {} max_features:\".format(m))\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "## Model performs well with all three max_features values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 2 max_depth: 1.000\n",
      "\n",
      "Classification report for 2 max_depth:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 5 max_depth: 1.000\n",
      "\n",
      "Classification report for 5 max_depth:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 10 max_depth: 1.000\n",
      "\n",
      "Classification report for 10 max_depth:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 20 max_depth: 1.000\n",
      "\n",
      "Classification report for 20 max_depth:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 40 max_depth: 1.000\n",
      "\n",
      "Classification report for 40 max_depth:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 60 max_depth: 1.000\n",
      "\n",
      "Classification report for 60 max_depth:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 100 max_depth: 1.000\n",
      "\n",
      "Classification report for 100 max_depth:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 200 max_depth: 1.000\n",
      "\n",
      "Classification report for 200 max_depth:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run RandomForestClassifier to find the optimum value for max_depth - maximum number of levels in the tree\n",
    "\n",
    "max_depth = [2, 5, 10, 20, 40, 60, 100, 200]\n",
    "\n",
    "for m in max_depth:\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=m, random_state = 42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    pred = rf_clf.predict(X_test)\n",
    "    print(\"Accuracy for {} max_depth: {:.3f}\\n\".format(m, accuracy_score(y_test, pred)))\n",
    "    print(\"Classification report for {} max_depth:\".format(m))\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "## Model performs well (possibly overfit) with all tested values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 2 min_samples_split: 1.000\n",
      "\n",
      "Classification report for 2 min_samples_split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 5 min_samples_split: 1.000\n",
      "\n",
      "Classification report for 5 min_samples_split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 8 min_samples_split: 0.750\n",
      "\n",
      "Classification report for 8 min_samples_split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.75      0.83      0.73         4\n",
      "weighted avg       0.88      0.75      0.77         4\n",
      "\n",
      "Accuracy for 10 min_samples_split: 0.750\n",
      "\n",
      "Classification report for 10 min_samples_split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.75      0.83      0.73         4\n",
      "weighted avg       0.88      0.75      0.77         4\n",
      "\n",
      "Accuracy for 15 min_samples_split: 0.250\n",
      "\n",
      "Classification report for 15 min_samples_split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.25         4\n",
      "   macro avg       0.12      0.50      0.20         4\n",
      "weighted avg       0.06      0.25      0.10         4\n",
      "\n",
      "Accuracy for 20 min_samples_split: 0.250\n",
      "\n",
      "Classification report for 20 min_samples_split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.25         4\n",
      "   macro avg       0.12      0.50      0.20         4\n",
      "weighted avg       0.06      0.25      0.10         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run RandomForestClassifier to find the optimum value for min_samples_split - minimum number of samples required to split a node\n",
    "\n",
    "min_samples_split = [2, 5, 8, 10, 15, 20]\n",
    "\n",
    "for m in min_samples_split:\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, min_samples_split=m, random_state = 42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    pred = rf_clf.predict(X_test)\n",
    "    print(\"Accuracy for {} min_samples_split: {:.3f}\\n\".format(m, accuracy_score(y_test, pred)))\n",
    "    print(\"Classification report for {} min_samples_split:\".format(m))\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "## Model performs best (without overfitting) with min_samples_split = 8, with performance decreasing as min_samples_split values increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 1 min_samples_leaf: 1.000\n",
      "\n",
      "Classification report for 1 min_samples_leaf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy for 2 min_samples_leaf: 0.750\n",
      "\n",
      "Classification report for 2 min_samples_leaf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.75      0.83      0.73         4\n",
      "weighted avg       0.88      0.75      0.77         4\n",
      "\n",
      "Accuracy for 5 min_samples_leaf: 0.250\n",
      "\n",
      "Classification report for 5 min_samples_leaf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.25         4\n",
      "   macro avg       0.12      0.50      0.20         4\n",
      "weighted avg       0.06      0.25      0.10         4\n",
      "\n",
      "Accuracy for 10 min_samples_leaf: 0.250\n",
      "\n",
      "Classification report for 10 min_samples_leaf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.25         4\n",
      "   macro avg       0.12      0.50      0.20         4\n",
      "weighted avg       0.06      0.25      0.10         4\n",
      "\n",
      "Accuracy for 15 min_samples_leaf: 0.250\n",
      "\n",
      "Classification report for 15 min_samples_leaf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.25         4\n",
      "   macro avg       0.12      0.50      0.20         4\n",
      "weighted avg       0.06      0.25      0.10         4\n",
      "\n",
      "Accuracy for 20 min_samples_leaf: 0.250\n",
      "\n",
      "Classification report for 20 min_samples_leaf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.25         4\n",
      "   macro avg       0.12      0.50      0.20         4\n",
      "weighted avg       0.06      0.25      0.10         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run RandomForestClassifier to find the optimum value for min_samples_leaf - minimum number of samples required at each leaf node\n",
    "\n",
    "min_samples_leaf = [1, 2, 5, 10, 15, 20]\n",
    "\n",
    "for m in min_samples_leaf: \n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=m, random_state = 42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    pred = rf_clf.predict(X_test)\n",
    "    print(\"Accuracy for {} min_samples_leaf: {:.3f}\\n\".format(m, accuracy_score(y_test, pred)))\n",
    "    print(\"Classification report for {} min_samples_leaf:\".format(m))\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "## min_samples_leaf = 1 shouldn't be used (overfitting), but model performs well with min_samples_leaf=2 (), and less well with all other values tested (accuracy = 0.250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 100 estimators: 0.75\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.75      0.83      0.73         4\n",
      "weighted avg       0.88      0.75      0.77         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run RandomForestClassifier with optimum hyperparameters (without overfitting) found above (where all tested hyperparameter values performed equally I have used the default value)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=10, min_samples_split=8, min_samples_leaf=2, random_state = 42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "print(\"Accuracy for {} estimators: {}\\n\".format(100, accuracy_score(y_test, pred)))\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 100 estimators: 1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier with optimum hyperparameters but possibly overfit\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators = 400, min_samples_split = 5,min_samples_leaf=1,max_features='sqrt',max_depth=30)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "print(\"Accuracy for {} estimators: {}\\n\".format(100, accuracy_score(y_test, pred)))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Question 3: Reflect on the importance of hyperparameter tuning of ML models based on your ML model development exercise**_\n",
    "\n",
    "Hyperparameter tuning is important for finding the best model and improving model accuracy and performance (i.e. improve the overall performance of the model). Finding the best suited hyperparameter values also helps to minimise overfitting a model. Overfitting occurs when a model fits the data too closely, leading to poor performance when applied to new data. Having a well fit and robust model helps to make sure the model will adapt well when presented with new data.\n",
    "\n",
    "In this question I have tuned the model by manipulating the hyper-parameters for the n_estimators, criterion, max_features, max_depth, min_samples_split, and min_samples_leaf.I used trial-and-error by looping through different values to see which produced the best results, taking into consideration that if the resulting model is too perfect this means it is likely overfit and will not perform well when presented with new data.\n",
    "\n",
    "These were my results for each of the parameters:\n",
    "\n",
    "n_estimators: Model performs acceptably with 10 estimators (without overfitting) and approaches perfect accuracy (overfit) with values over 20. The values I tried were n_estimators = 10, 20, 50, 100, 500, 1000, 2000\n",
    "\n",
    "criterion: Model performs will with all three criterion values ('gini', 'entropy', 'log_loss')\n",
    "\n",
    "max_features: Model performs well with all three max_features values ('sqrt', 'log2', None)\n",
    "\n",
    "max_depth: Model performs well (but may be possibly overfit) with all tested values (max_depth = 2, 5, 10, 20, 40, 60, 100, 200)\n",
    "\n",
    "min_samples_split: Model performs best (without overfitting) with min_samples_split = 8, with performance decreasing as min_samples_split values increase. I tried values min_samples_split = 2, 5, 8, 10, 15, 20\n",
    "\n",
    "min_samples_leaf: Model performs well with min_samples_leaf=2 (), and less well with all other values tested (accuracy = 0.250). I tried values min_samples_leaf = 1, 2, 5, 10, 15, 20. I did not try min_samples = 1 because this is more likely to lead to overfitting.\n",
    "\n",
    "The optimum hyper-parameter values were then combined for the final tuned model, which performed too well and is possibly still overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Question 4: Create a GradientBoost model for the predicting Result using the same dataset that you have used Q1 and report the performance.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "df = pd.read_csv(\"../data/data_9.csv\")\n",
    "\n",
    "# Split the data into X and y\n",
    "X = df.drop('Result', axis=1)\n",
    "y = df.Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 100 estimators: 1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "gbc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbc_model.predict(X_test)\n",
    "print(\"Accuracy for {} estimators: {}\\n\".format(100, accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 100 estimators: 1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=10, learning_rate=0.01, random_state=42)\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = abc.predict(X_test)\n",
    "print(\"Accuracy for {} estimators: {}\\n\".format(100, accuracy_score(y_test, pred)))\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0814b1b1b74bea909dbe3aef7ef1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='n_estimators', options=(10, 110, 210, 310, 410, 510, 610, 710), vaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def conmat(y_test, pred):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)\n",
    "    _ = ax.set_title(\n",
    "        f\"Confusion Matrix for {rf_clf.__class__.__name__}\"\n",
    "    )\n",
    "\n",
    "def f(n_estimators,learning_rate):\n",
    "    abc =AdaBoostClassifier(n_estimators=n_estimators,learning_rate=learning_rate, random_state=0)\n",
    "    abc.fit(X_train, y_train)\n",
    "    pred = abc.predict(X_test)\n",
    "    conmat(y_test, pred)\n",
    "    print('The accuracy of the RF classifier on test data is {:.2f} out of 1 '.format(abc.score(X_test, y_test)))\n",
    "    \n",
    "interact(f,learning_rate=np.arange(0.1,1,0.1),n_estimators=np.arange(10,800,100));\n",
    "\n",
    "\n",
    "## The confusion matrix below shows that the model has correctly classified 4 out of 4 samples in the test set (three samples for class 0 and one sample for class 1, shown in yellow and teal).\n",
    "## None of the samples in the test set were incorrectly classified (shown in purple).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Question 5: Compare the performance of two models (Q1 and Q4). Explain which model is good and why**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier and AdaBoost are both ensemble learning algorithms, meaning both create models by training lots of decision trees (each with a slightly different subset of the data). These trees are then combined (in different ways depending on the model and type of data) to create the model. RandomForestClassifier and AdaBoost differ in a few ways:\n",
    "- RandomForestClassifier creates a forest of decision trees whereas AdaBoost creates a forest of decision stumps (decision trees with one node and two leaves).\n",
    "- RandomForestClassifier builds each tree independently, whereas AdaBoost builds each tree sequentially and adjust the weights of the misclassified samples in each iteration (to ensure misclassified samples are picked up in the next iteration)\n",
    "\n",
    "Here, both models performed well. However, the model created using AdaBoost in question 4 runs faster than the model created using RandomForestClassifier question 1, possibly indicating greater efficiency in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
